# Pre-Milestone Mini-Sprint: Scoring & AI-Tag Generation Logic (M1.11.5)

**Parent Milestone:** M1.11.5 ¬∑ Scoring & AI-Tag Generation Logic\
**Epic:** 1.11 ¬∑ Onboarding Intake Surveys\
**Status:** üöß _Proposed_\
**Priority:** High ‚Äì Close specification gaps before coding starts

---

## üéØ Sprint Goal

Ensure the scoring algorithm, data models, and Supabase integration are fully
specified, testable, and performance-ready so that implementation can begin with
clear, measurable requirements.

---

## Resources Available

- Scoring rules table:
  `docs/MVP_ROADMAP/1-11 Onboarding/Onboarding_Survey_Scoring.md`
- Previous milestone outputs (tables from **M1.11.1**)
- Supabase Edge Function examples under `supabase/functions/`
- Architecture & coding rules in `.cursor/rules/`

---

## üõ†Ô∏è Action Items

| ID     | Task                                                                                                              | Owner          | Est. Time | Status       |
| ------ | ----------------------------------------------------------------------------------------------------------------- | -------------- | --------- | ------------ |
| **A1** | Finalise end-to-end scoring mapping (produce CSV/JSON fixtures for all permutations)                              | Algorithm Lead | 1 h       | ‚úÖ Completed |
| **A2** | Define Dart data models (`MotivationType`, `ReadinessLevel`, `CoachStyle`) using `freezed`; add to `core/models/` | State Lead     | 1 h       | ‚úÖ Completed |
| **A3** | Verify presence of Edge Function emulator; if missing, document alternative contract-test strategy                | BE Lead        | 0.5 h     | ‚úÖ Completed |
| **A4** | Validate `coach_memory` table schema; create migration for tag fields if absent                                   | DB Lead        | 1 h       | ‚úÖ Completed |
| **A5** | Draft benchmark script (`flutter test --enable-benchmark`) and CI step for latency metrics                        | QA Lead        | 0.5 h     | ‚úÖ Completed |
| **A6** | Update / draft OpenAPI spec for `POST /sync-ai-tags`                                                              | API Lead       | 0.5 h     | ‚úÖ Completed |
| **A7** | Document error handling & idempotency strategy for Edge Function (e.g., duplicate submissions)                    | BE Lead        | 0.5 h     | ‚úÖ Completed |

---

## üì¶ Deliverables

1. Scoring mapping fixtures (`test/fixtures/scoring_cases.json`).
2. New/updated Dart models (`core/models/`), passing analysis.
3. Confirmation or replacement of Edge Function emulator workflow.
4. Database migration file (if required) & updated Prisma/SQL docs.
5. Benchmark script and CI job addition.
6. Updated OpenAPI YAML fragment under `docs/api/`.
7. Error-handling guidelines in Edge Function README.

---

## ‚úÖ Success Criteria

- Fixtures load and drive unit tests without missing permutations.
- Dart models compile with `--fatal-warnings` and are fully nullable-safe.
- Contract-test pathway agreed (emulator or alternative stub) and documented.
- Database migration applies cleanly locally & in CI.
- Benchmark script shows scoring service cold-start latency <50 ms on CI runner.
- OpenAPI diff passes lint & preview.

---

## ‚è± Suggested Timeline _(total ‚âà 5 h)_

| Day       | Morning | Afternoon            |
| --------- | ------- | -------------------- |
| **Day 1** | A1, A2  | A3, A4               |
| **Day 2** | A5, A6  | A7, buffer / reviews |

---

## üîÑ Post-Sprint Actions

1. Merge updates into milestone branch.
2. Re-run readiness audit ‚Äì expect ‚úÖ PASS.
