# BEE Engagement Events - Testing Suite

**Module:** Core Engagement\
**Milestone:** 1 ¬∑ Data Backbone\
**Task:** 5 - Testing & Validation

This directory contains comprehensive tests for the engagement events logging
system, covering database security, performance, and API validation.

## üìã Test Overview

### Task 5.1: Mock Data Generation ‚úÖ

- **File:** `supabase/migrations/seed_engagement_events.sql`
- **Purpose:** Generate realistic test data with multiple event types and users
- **Coverage:** ~48 events across 3 test users with varied JSONB payloads

### Task 5.2: RLS Audit Tests ‚úÖ

- **File:** `tests/db/test_rls_audit.py`
- **Purpose:** Verify complete cross-user data isolation
- **Coverage:** Zero cross-user leakage verification, concurrent session testing

### Task 5.3: Performance Testing ‚úÖ

- **File:** `tests/db/test_performance.py`
- **Purpose:** Measure database performance and Realtime latency
- **Coverage:** Concurrent inserts, index effectiveness, large dataset queries

### Task 5.4: API Validation Tests ‚úÖ

- **File:** `tests/api/test_api_validation.py`
- **Purpose:** Test REST/GraphQL APIs, authentication, and error handling
- **Coverage:** CRUD operations, unauthorized access, rate limiting

## üöÄ Quick Start

### Prerequisites

1. **Install Dependencies:**
   ```bash
   pip install -r tests/requirements.txt
   ```

2. **Environment Setup:**
   ```bash
   # Required for database tests
   export DB_HOST=localhost
   export DB_PORT=54322
   export DB_NAME=postgres
   export DB_USER=postgres
   export DB_PASSWORD=postgres

   # Optional for API tests
   export SUPABASE_URL=http://localhost:54321
   export SUPABASE_ANON_KEY=your_anon_key
   export USER_JWT_TOKEN=your_user_jwt
   export SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
   ```

3. **Database Setup:**
   ```bash
   # Apply migrations
   supabase db reset

   # Load test data
   psql -h localhost -p 54322 -U postgres -d postgres -f supabase/migrations/seed_engagement_events.sql
   ```

### Run All Tests

```bash
# Run complete test suite
python tests/run_all_tests.py

# Run with options
python tests/run_all_tests.py --skip-performance --skip-api
```

### Run Individual Test Suites

```bash
# RLS Audit Tests
python tests/db/test_rls_audit.py

# Performance Tests  
python tests/db/test_performance.py

# API Validation Tests
python tests/api/test_api_validation.py
```

## üìä Test Details

### RLS Audit Tests (`test_rls_audit.py`)

**Purpose:** Ensure HIPAA-compliant data isolation

**Tests:**

1. **Table & RLS Check** - Verify engagement_events table exists with RLS
   enabled
2. **User Isolation** - Confirm users can only see their own events
3. **Anonymous Access** - Verify anonymous users have no access
4. **Insert Isolation** - Test users can only insert their own events
5. **Service Role Access** - Verify service role bypasses RLS appropriately
6. **Concurrent Sessions** - Test RLS under concurrent user access

**Success Criteria:**

- Zero cross-user data leakage
- All RLS policies enforced correctly
- Service role access works for bulk operations

### Performance Tests (`test_performance.py`)

**Purpose:** Validate system performance under load

**Tests:**

1. **Single Insert Performance** - Target: <50ms average
2. **Concurrent Inserts** - 100+ concurrent inserts, >50 inserts/sec
3. **Index Effectiveness** - Verify EXPLAIN ANALYZE shows index usage
4. **Large Dataset Queries** - Test with 1000+ events, <500ms queries
5. **Realtime Latency** - Simulate <500ms notification latency

**Success Criteria:**

- Meet all performance targets from PRD
- Indexes used effectively for common queries
- System scales under concurrent load

### API Validation Tests (`test_api_validation.py`)

**Purpose:** Validate REST and GraphQL API behavior

**Tests:**

1. **REST CRUD Operations** - Test all HTTP methods with authentication
2. **GraphQL Operations** - Test queries and mutations
3. **Unauthorized Access** - Verify proper error responses (401/403)
4. **Service Role Access** - Test bulk operations and RLS bypass
5. **Data Validation** - Test constraint enforcement and error handling
6. **Rate Limiting** - Test API behavior under rapid requests
7. **Response Formats** - Validate JSON structure and data types

**Success Criteria:**

- All CRUD operations work correctly
- Proper authentication and authorization
- Consistent API response formats

## üìà Test Reports

Each test suite generates detailed JSON reports:

- **RLS Audit:** `tests/db/rls_audit_report_YYYYMMDD_HHMMSS.json`
- **Performance:** `tests/db/performance_report_YYYYMMDD_HHMMSS.json`
- **API Validation:** `tests/api/api_validation_report_YYYYMMDD_HHMMSS.json`

## üîß Troubleshooting

### Common Issues

1. **Database Connection Failed**
   ```bash
   # Check if Supabase is running
   supabase status

   # Start local development
   supabase start
   ```

2. **Missing Test Data**
   ```bash
   # Reload seed data
   psql -h localhost -p 54322 -U postgres -d postgres -f supabase/migrations/seed_engagement_events.sql
   ```

3. **API Tests Failing**
   ```bash
   # Check environment variables
   echo $SUPABASE_URL
   echo $SUPABASE_ANON_KEY

   # Generate user JWT token for testing
   # (Use Supabase dashboard or auth endpoint)
   ```

4. **Permission Errors**
   ```bash
   # Make scripts executable
   chmod +x tests/db/test_rls_audit.py
   chmod +x tests/db/test_performance.py
   chmod +x tests/api/test_api_validation.py
   ```

### Environment Variables Reference

| Variable                    | Required | Purpose              | Default                         |
| --------------------------- | -------- | -------------------- | ------------------------------- |
| `DB_HOST`                   | Yes      | Database host        | `localhost`                     |
| `DB_PORT`                   | Yes      | Database port        | `54322`                         |
| `DB_NAME`                   | Yes      | Database name        | `postgres`                      |
| `DB_USER`                   | Yes      | Database user        | `postgres`                      |
| `DB_PASSWORD`               | Yes      | Database password    | `postgres`                      |
| `SUPABASE_URL`              | No       | Supabase project URL | `http://localhost:54321`        |
| `SUPABASE_ANON_KEY`         | No       | Anonymous API key    | Required for API tests          |
| `USER_JWT_TOKEN`            | No       | User JWT for testing | Required for user API tests     |
| `SUPABASE_SERVICE_ROLE_KEY` | No       | Service role key     | Required for service role tests |

## üéØ Success Metrics

Task 5 is complete when all tests pass:

- ‚úÖ **RLS Audit:** Zero cross-user leakage confirmed
- ‚úÖ **Performance:** <500ms Realtime latency, >50 inserts/sec throughput
- ‚úÖ **API Validation:** All CRUD operations working with proper auth

## üìö Related Documentation

- **PRD:** `docs/1_milestone_1/prd-engagement-events-logging.md`
- **Tasks:** `docs/1_milestone_1/tasks-prd-engagement-events-logging.md`
- **Prompts:** `docs/1_milestone_1/prompts-engagement-events.md`
- **Migration:** `supabase/migrations/20241201000000_engagement_events.sql`

## üöß Known Limitations / Future Work

- **Skipped DB Performance & RLS Suites:** The heavy database-performance tests
  (`test_performance_optimization.py`) and the RLS integration suite
  (`test_rls.py`) are temporarily marked with `@pytest.mark.skip` in CI. They
  require a seeded `auth.users` table and additional fixtures (non-superuser
  role, engagement_events schema) that are not yet provisioned by our GitHub
  Actions workflow.

  **Action Item (Module 2 ¬∑ Data Integration & Events ‚áí Task 5.x):** Implement a
  lightweight seed-data generator (or mock fixtures) during pipeline setup, then
  remove the skip markers to restore full coverage.

---

**Status:** ‚úÖ Complete\
**Next:** Proceed to Task 6 (Documentation & Deployment)

## üìê UI Latency Measurement ‚Äì LikertSelector (Onboarding)

### Purpose

Verify that selecting an option in the LikertSelector completes in **< 50 ms
(p95)** on target devices (Pixel 4 & iPhone 11). This ensures instant feedback
to the user and meets UX performance SLAs.

### Measurement Method

1. **Integration Test**
   (`app/test/integration/likert_selector_latency_test.dart`)
   - Uses `integration_test` + `flutter_test` with `traceAction` to record a
     performance timeline while executing a `tester.tap` on each radio option.
   - Extracts `frameBuildTimeMillis` & `frameRasterizerTimeMillis` from the
     `TimelineSummary`.
   - Fails the test if **max** build or raster time > 50 ms.
2. **Manual Bench** (optional)
   - Run the test on physical devices with:\
     `flutter test integration_test/likert_selector_latency_test.dart --profile --trace-startup`
   - Inspect generated summary `build/summary.json` for frame timings.

### Pass/Fail Criteria

| Metric                            | Target  |
| --------------------------------- | ------- |
| `frameBuildTimeMillis (p95)`      | < 50 ms |
| `frameRasterizerTimeMillis (p95)` | < 8 ms  |

### Sample Integration Test Snippet

```dart
import 'package:integration_test/integration_test.dart';
import 'package:flutter_test/flutter_test.dart';
import 'package:app/main.dart' as app;

void main() {
  IntegrationTestWidgetsFlutterBinding.ensureInitialized();

  testWidgets('LikertSelector tap latency <50ms', (tester) async {
    await app.main();
    await tester.pumpAndSettle();

    final summary = await tester.traceAction(() async {
      final option = find.byKey(const ValueKey('likert_option_3'));
      await tester.tap(option);
      await tester.pumpAndSettle();
    });

    expect(summary.summaryJson!['frameBuildTimeMillis']['p95'] as num < 50, isTrue);
  });
}
```

### CI Hook

The test will run in profile mode on GitHub Actions ‚Äúmobile-integ‚Äù job. Failures
block merge.

---
